{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT to the rescue.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_FXneEfpdMM",
        "colab_type": "code",
        "outputId": "ff8057f1-23dc-49b8-b11c-f68823bf6f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "tags": []
      },
      "source": [
        "# !pip install pytorch-nlp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting pytorch-nlp\n  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n\u001b[K     |████████████████████████████████| 90 kB 1.4 MB/s \n\u001b[?25hRequirement already satisfied: numpy in /Users/andrewmendez1/.local/lib/python3.6/site-packages (from pytorch-nlp) (1.18.1)\nRequirement already satisfied: tqdm in /Users/andrewmendez1/anaconda3/envs/gsa_eula_env/lib/python3.6/site-packages (from pytorch-nlp) (4.48.0)\nInstalling collected packages: pytorch-nlp\nSuccessfully installed pytorch-nlp-0.5.0\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c8e3d88-13b0-4652-973d-3fa2c023e48e",
        "id": "EnVIV6Vt8f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "tags": []
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import torch\n",
        "# from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "# from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torchtext\n",
        "# import torchtext.data\n",
        "# # import torch.nn as nn\n",
        "# # import torch.nn.functional as F\n",
        "\n",
        "# from torchtext.vocab import Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEXT = torchtext.data.Field(lower=True, tokenize='spacy')\n",
        "# Label = torchtext.data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUYrv06z8gaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rn.seed(321)\n",
        "np.random.seed(321)\n",
        "torch.manual_seed(321)\n",
        "torch.cuda.manual_seed(321)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgkbhHcB17GY",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ur8i7boP6qtb",
        "colab": {},
        "tags": []
      },
      "source": [
        "train_data, test_data = imdb_dataset(train=True, test=True)\n",
        "rn.shuffle(train_data)\n",
        "rn.shuffle(test_data)\n",
        "train_data = train_data[:1000]# only 1000 examples!!!\n",
        "test_data = test_data[:100]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "aclImdb_v1.tar.gz: 84.1MB [00:25, 3.28MB/s]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"This movie brings back many memories of the classic cinema of old, where actors didn't have to take their clothes off to make viewers watch their film.<br /><br />Firstly I think the main plus point of this movie is the amazing chemistry between Shahid and Amrita, it is definitely the making of the film.<br /><br />I have seen lots of comments regarding the film being sickly sweet and overly slushy. In response to this, I think to a certain degree this is a correct analysis, however considering this is a Barjatya film I think that compared to MPK, HAHK, HSSH and MPKDH, it has been toned down significantly. HSSH was almost unbearable to watch in some places.<br /><br />In this film however, when the sentimental moments come along, you find yourself smiling, wishing the budding couple all the best and hoping that nothing bad happens to them.<br /><br />Another major plus point is the performances of Shahid and Amrita. Both have acted very well, especially Shahid who looks great in the film. Amrita looks simply stunning and should be taken seriously as a future major star.<br /><br />Although I really enjoyed the film as a whole, I do feel that it was too long. Some of the middle could have been trimmed off and it would maybe made even more of an impact. I also think the music, although it fits into the film when you see the situations is slightly old fashioned and the movie could have benefited if a more up-to-date soundtrack had been available. Although the picturisation of the songs Mujhe Haq Hain and Hamari Shaadi Mein are wonderful.<br /><br />All in all, I definitely recommend this film, its romantic, looks stunning and has a dramatic climax (I won't go into details, just in case you haven't seen it.<br /><br />PS. If you're prone to crying-take a tissue! (I needed several)\""
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_data[0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'pos'"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_data[0]['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'zip' object has no attribute 'iter'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e777a4fe91da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'zip' object has no attribute 'iter'"
          ]
        }
      ],
      "source": [
        "# zip(*map(lambda d: (d['text'], d['sentiment']), train_data)).iter()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1VENo6tqG7J",
        "colab_type": "code",
        "outputId": "5f10799f-d17d-42fd-a4c2-c760b61f7ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), train_data)))\n",
        "test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['sentiment']), test_data)))\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1000, 1000, 100, 100)"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "1000"
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(train_texts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty24UrRjqIsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26trq3gIrJeG",
        "colab_type": "code",
        "outputId": "196b2aa3-0176-4010-baf8-e650ca0da658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.tokenize('Hi my name is Dima')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['hi', 'my', 'name', 'is', 'dim', '##a']"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "gsa = '18. Governing Law: This Agreement shall be governed by and interpreted in accordance with the Federal laws of theUnited States, without reference to conflict-of-laws principles. If for any reason a court of competent jurisdiction finds any provision of this Agreement to be unenforceable, that provision will be enforced to the maximum extent possible to effectuate the intent of the parties, and the remainder of this Agreement will continue in full force and effect. This Agreement shall not be governed by the United Nations Convention on Contracts for the International Sale of Goods. Buyer agrees that exclusive jurisdiction for any dispute arising out of or relating to this Agreement lies within the venue mandated by applicable Federal law.'\n",
        "# tokenizer.tokenize(gsa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[[101,\n  2324,\n  1012,\n  8677,\n  2375,\n  1024,\n  2023,\n  3820,\n  4618,\n  2022,\n  9950,\n  2011,\n  1998,\n  10009,\n  1999,\n  10388,\n  2007,\n  1996,\n  2976,\n  4277,\n  1997,\n  1996,\n  19496,\n  3064,\n  2163,\n  1010,\n  2302,\n  4431,\n  2000,\n  4736,\n  1011,\n  1997,\n  1011,\n  4277,\n  6481,\n  1012,\n  2065,\n  2005,\n  2151,\n  3114,\n  1037,\n  2457,\n  1997,\n  17824,\n  7360,\n  4858,\n  2151,\n  9347,\n  1997,\n  2023,\n  3820,\n  2000,\n  2022,\n  16655,\n  2078,\n  14821,\n  3085,\n  1010,\n  2008,\n  9347,\n  2097,\n  2022,\n  16348,\n  2000,\n  1996,\n  4555,\n  6698,\n  2825,\n  2000,\n  3466,\n  20598,\n  1996,\n  7848,\n  1997,\n  1996,\n  4243,\n  1010,\n  1998,\n  1996,\n  6893,\n  1997,\n  2023,\n  3820,\n  2097,\n  3613,\n  1999,\n  2440,\n  2486,\n  1998,\n  3466,\n  1012,\n  2023,\n  3820,\n  4618,\n  2025,\n  2022,\n  9950,\n  2011,\n  1996,\n  2142,\n  3741,\n  4680,\n  2006,\n  8311,\n  2005,\n  1996,\n  2248,\n  5096,\n  1997,\n  5350,\n  1012,\n  17634,\n  10217,\n  2008,\n  7262,\n  7360,\n  2005,\n  2151,\n  7593,\n  17707,\n  2041,\n  1997,\n  2030,\n  8800,\n  2000,\n  2023,\n  3820,\n  3658,\n  2306,\n  1996,\n  6891,\n  16714,\n  2011,\n  12711,\n  2976,\n  2375,\n  1012,\n  102]]"
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# gsa after BertTokenizer\n",
        "tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], [gsa]))\n",
        "train_token_id_gsa = list(map(tokenizer.convert_tokens_to_ids, tokens))\n",
        "train_token_id_gsa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k9rcOzQr5Zm",
        "colab_type": "code",
        "outputId": "b9b59a4e-57bd-4e9c-fcd1-2a4ba1fadc0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], test_texts))\n",
        "\n",
        "len(train_tokens), len(test_tokens)                   \n",
        "                   "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1000, 100)"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ca7KKnhuT5c",
        "colab_type": "code",
        "outputId": "69ba3b87-4d86-448b-c9cb-7be8361182f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1000, 512), (100, 512))"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a5447340-6da3-4f2c-d284-098c4c906c47",
        "id": "F7POtHuIOV-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y = np.array(train_labels) == 'pos'\n",
        "test_y = np.array(test_labels) == 'pos'\n",
        "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1000,), (100,), 0.489, 0.5)"
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [[float(i > 0) for i in ii] for ii in train_tokens_ids]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-xXMEqXOWTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4JQMFo1-_S",
        "colab_type": "text"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdzjl_WlwpKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jyb-hJ0xAgG",
        "colab_type": "code",
        "outputId": "4cc5ca8c-646f-410f-d5c5-998fdf82f00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "baseline_model = make_pipeline(TfidfVectorizer(ngram_range=(1,3)), LogisticRegression()).fit(train_texts, train_labels)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9IzjAX_2VLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline_predicted = baseline_model.predict(test_texts)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsCRIaQ3GPQ",
        "colab_type": "code",
        "outputId": "46417074-2870-4a52-9a6a-307bde86b704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "tags": []
      },
      "source": [
        "print(classification_report(test_labels, baseline_predicted))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "precision    recall  f1-score   support\n\n         neg       0.75      0.90      0.82        50\n         pos       0.88      0.70      0.78        50\n\n    accuracy                           0.80       100\n   macro avg       0.81      0.80      0.80       100\nweighted avg       0.81      0.80      0.80       100\n\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_hEhebQ3YqI",
        "colab_type": "text"
      },
      "source": [
        "# Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E234ByBa3Qtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        # _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba\n",
        "        "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED9SE1Ka8W9x",
        "colab_type": "code",
        "outputId": "ab8b549b-137b-491a-cf6f-f20718dd73ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cpu')"
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZ_3auqDbjl",
        "colab_type": "code",
        "outputId": "1c20ee58-abb4-4bf2-f79a-851ab54c31eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sf9n8zouENRi",
        "colab": {},
        "tags": []
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "# bert_clf = bert_clf.cuda()\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbHkaJuZEkYr",
        "colab_type": "code",
        "outputId": "dff4b8e7-db91-46de-8b8c-bf0cddccaba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'439.065088M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOQ-870M7VWy",
        "colab_type": "code",
        "outputId": "f7c010bf-eb70-413f-96db-c0eb14769cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor(train_tokens_ids[:3]).to(device)\n",
        "# y, pooled = bert_clf.bert(x, output_all_encoded_layers=False)\n",
        "y, pooled = bert_clf.bert(x)\n",
        "x.shape, y.shape, pooled.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(torch.Size([3, 512]), torch.Size([3, 512, 768]), torch.Size([3, 768]))"
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCb_pK4X7hb9",
        "colab_type": "code",
        "outputId": "77237549-1b51-4d51-a11e-84e53fa82cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = bert_clf(x)\n",
        "y.cpu().detach().numpy()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.5170465],\n       [0.5997109],\n       [0.524293 ]], dtype=float32)"
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUm-gFCuFkoI",
        "colab_type": "code",
        "outputId": "4cac9ca3-1080-4307-81a4-d2a7d7618eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6698.214912M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzsUZOUFcxp",
        "colab_type": "code",
        "outputId": "fdb38786-4df8-473d-cf45-f635741a868e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# y, x, pooled = None, None, None\n",
        "# torch.cuda.empty_cache()\n",
        "# str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9LPIYcn99r8",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUkXhM1k_TAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGwV0yqg_o2u",
        "colab_type": "code",
        "outputId": "236eae60-f405-4f2b-89be-1164fb924b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "\n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "train_masks_tensor = torch.tensor(train_masks)\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "# str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yl2JpCe9YAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF_QD0naS8EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(bert_clf.sigmoid.named_parameters()) \n",
        "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28PcoDh_cyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(bert_clf.parameters(), lr=3e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6yIChYvBP5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqh8tCl4AFjo",
        "colab_type": "code",
        "outputId": "15c746cf-ba17-483a-d0ff-0bcbf9e96431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "tags": []
      },
      "source": [
        "for epoch_num in range(EPOCHS):\n",
        "    bert_clf.train()\n",
        "    train_loss = 0\n",
        "    for step_num, batch_data in enumerate(train_dataloader):\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "        # print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        \n",
        "        loss_func = nn.BCELoss()\n",
        "\n",
        "        batch_loss = loss_func(logits, labels)\n",
        "        train_loss += batch_loss.item()\n",
        "        \n",
        "        \n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        \n",
        "\n",
        "        clip_grad_norm_(parameters=bert_clf.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        print('Epoch: ', epoch_num + 1)\n",
        "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHFWhkRYHv5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf.eval()\n",
        "bert_predicted = []\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "        loss_func = nn.BCELoss()\n",
        "        loss = loss_func(logits, labels)\n",
        "        numpy_logits = logits.cpu().detach().numpy()\n",
        "        \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
        "        all_logits += list(numpy_logits[:, 0])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg_sX9BjooL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e85f485-c125-4ed6-bb8a-07ed708c54f9"
      },
      "source": [
        "np.mean(bert_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DmIJqUnkVM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "de735d0b-ad04-4d81-ef14-c6394bab92d1"
      },
      "source": [
        "print(classification_report(test_y, bert_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIBvoExLpOne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all 12 hidden states\n",
        "# source: https://github.com/huggingface/transformers/issues/1827\n",
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "\n",
        "outputs = model(inputs)\n",
        "print(len(outputs))  # 3\n",
        "\n",
        "hidden_states = outputs[2]\n",
        "print(len(hidden_states))  # 13\n",
        "\n",
        "embedding_output = hidden_states[0]\n",
        "attention_hidden_states = hidden_states[1:]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6ab9092fe027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}